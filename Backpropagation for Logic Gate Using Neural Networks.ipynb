{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AND Gate**"
      ],
      "metadata": {
        "id": "TdmVn6MDXY22"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-1PHzEbXYKG",
        "outputId": "435c548c-3071-4864-a740-7fa035d4ded8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input\tPredicted Output\n",
            "[0 0] \t 0\n",
            "[0 1] \t 0\n",
            "[1 0] \t 0\n",
            "[1 1] \t 1\n",
            "\n",
            "Final Weights:\n",
            "w0: -8.32087927933914\n",
            "w1: 5.485476003016963\n",
            "w2: 5.485475996477335\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the sigmoid function and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training data\n",
        "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_train = np.array([[0], [0], [0], [1]])  # AND gate truth table\n",
        "\n",
        "# Initialize weights and bias\n",
        "w0 = np.random.randn()\n",
        "w1 = np.random.randn()\n",
        "w2 = np.random.randn()\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Training the neural network\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "    predictions = sigmoid(weighted_sum)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = y_train.flatten() - predictions\n",
        "\n",
        "    # Calculate gradients\n",
        "    d_predictions = error * sigmoid_derivative(predictions)\n",
        "    d_w0 = np.sum(d_predictions)\n",
        "    d_w1 = np.dot(X_train[:, 0], d_predictions)\n",
        "    d_w2 = np.dot(X_train[:, 1], d_predictions)\n",
        "\n",
        "    # Update weights and bias\n",
        "    w0 += learning_rate * d_w0\n",
        "    w1 += learning_rate * d_w1\n",
        "    w2 += learning_rate * d_w2\n",
        "\n",
        "# After training, print the results\n",
        "weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "predictions = sigmoid(weighted_sum)\n",
        "\n",
        "print(\"Input\\tPredicted Output\")\n",
        "for i in range(len(X_train)):\n",
        "    if predictions[i] < 0.5:\n",
        "        print(X_train[i], \"\\t\", \"0\")\n",
        "    else:\n",
        "        print(X_train[i], \"\\t\", \"1\")\n",
        "\n",
        "print(\"\\nFinal Weights:\")\n",
        "print(\"w0:\", w0)\n",
        "print(\"w1:\", w1)\n",
        "print(\"w2:\", w2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OR Gate**"
      ],
      "metadata": {
        "id": "-EU-06WAXqtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the sigmoid function and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training data\n",
        "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_train = np.array([[0], [1], [1], [1]])  # OR gate truth table\n",
        "\n",
        "# Initialize weights and bias\n",
        "w0 = np.random.randn()\n",
        "w1 = np.random.randn()\n",
        "w2 = np.random.randn()\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Training the neural network\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "    predictions = sigmoid(weighted_sum)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = y_train.flatten() - predictions\n",
        "\n",
        "    # Calculate gradients\n",
        "    d_predictions = error * sigmoid_derivative(predictions)\n",
        "    d_w0 = np.sum(d_predictions)\n",
        "    d_w1 = np.dot(X_train[:, 0], d_predictions)\n",
        "    d_w2 = np.dot(X_train[:, 1], d_predictions)\n",
        "\n",
        "    # Update weights and bias\n",
        "    w0 += learning_rate * d_w0\n",
        "    w1 += learning_rate * d_w1\n",
        "    w2 += learning_rate * d_w2\n",
        "\n",
        "# After training, print the results\n",
        "weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "predictions = sigmoid(weighted_sum)\n",
        "\n",
        "print(\"Input\\tPredicted Output\")\n",
        "for i in range(len(X_train)):\n",
        "    if predictions[i] < 0.5:\n",
        "        print(X_train[i], \"\\t\", \"0\")\n",
        "    else:\n",
        "        print(X_train[i], \"\\t\", \"1\")\n",
        "\n",
        "print(\"\\nFinal Weights:\")\n",
        "print(\"w0:\", w0)\n",
        "print(\"w1:\", w1)\n",
        "print(\"w2:\", w2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OArSOj8pXlRW",
        "outputId": "0fea0ce3-74da-47e7-be07-5a13a522fb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input\tPredicted Output\n",
            "[0 0] \t 0\n",
            "[0 1] \t 1\n",
            "[1 0] \t 1\n",
            "[1 1] \t 1\n",
            "\n",
            "Final Weights:\n",
            "w0: -2.8415642870147835\n",
            "w1: 6.175602214777425\n",
            "w2: 6.175467881072194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAND Gate**"
      ],
      "metadata": {
        "id": "gvrRZJUNYI89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the sigmoid function and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training data\n",
        "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_train = np.array([[1], [1], [1], [0]])  # NAND gate truth table\n",
        "\n",
        "# Initialize weights and bias\n",
        "w0 = np.random.randn()\n",
        "w1 = np.random.randn()\n",
        "w2 = np.random.randn()\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Training the neural network\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "    predictions = sigmoid(weighted_sum)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = y_train.flatten() - predictions\n",
        "\n",
        "    # Calculate gradients\n",
        "    d_predictions = error * sigmoid_derivative(predictions)\n",
        "    d_w0 = np.sum(d_predictions)\n",
        "    d_w1 = np.dot(X_train[:, 0], d_predictions)\n",
        "    d_w2 = np.dot(X_train[:, 1], d_predictions)\n",
        "\n",
        "    # Update weights and bias\n",
        "    w0 += learning_rate * d_w0\n",
        "    w1 += learning_rate * d_w1\n",
        "    w2 += learning_rate * d_w2\n",
        "\n",
        "# After training, print the results\n",
        "weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "predictions = sigmoid(weighted_sum)\n",
        "\n",
        "print(\"Input\\tPredicted Output\")\n",
        "for i in range(len(X_train)):\n",
        "    if predictions[i] < 0.5:\n",
        "        print(X_train[i], \"\\t\", \"0\")\n",
        "    else:\n",
        "        print(X_train[i], \"\\t\", \"1\")\n",
        "\n",
        "print(\"\\nFinal Weights:\")\n",
        "print(\"w0:\", w0)\n",
        "print(\"w1:\", w1)\n",
        "print(\"w2:\", w2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LUPJQXXYHeI",
        "outputId": "47d360e1-a068-495c-9457-a59012e47610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input\tPredicted Output\n",
            "[0 0] \t 1\n",
            "[0 1] \t 1\n",
            "[1 0] \t 1\n",
            "[1 1] \t 0\n",
            "\n",
            "Final Weights:\n",
            "w0: 8.316364820851033\n",
            "w1: -5.482457482043787\n",
            "w2: -5.482457401932816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOR Gate"
      ],
      "metadata": {
        "id": "dNpaiNBiYh4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the sigmoid function and its derivative\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training data\n",
        "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_train = np.array([[1], [0], [0], [0]])  # NOR gate truth table\n",
        "\n",
        "# Initialize weights and bias\n",
        "w0 = np.random.randn()\n",
        "w1 = np.random.randn()\n",
        "w2 = np.random.randn()\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Training the neural network\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "    predictions = sigmoid(weighted_sum)\n",
        "\n",
        "    # Calculate the error\n",
        "    error = y_train.flatten() - predictions\n",
        "\n",
        "    # Calculate gradients\n",
        "    d_predictions = error * sigmoid_derivative(predictions)\n",
        "    d_w0 = np.sum(d_predictions)\n",
        "    d_w1 = np.dot(X_train[:, 0], d_predictions)\n",
        "    d_w2 = np.dot(X_train[:, 1], d_predictions)\n",
        "\n",
        "    # Update weights and bias\n",
        "    w0 += learning_rate * d_w0\n",
        "    w1 += learning_rate * d_w1\n",
        "    w2 += learning_rate * d_w2\n",
        "\n",
        "# After training, print the results\n",
        "weighted_sum = w0 + np.dot(X_train[:, 0], w1) + np.dot(X_train[:, 1], w2)\n",
        "predictions = sigmoid(weighted_sum)\n",
        "\n",
        "print(\"Input\\tPredicted Output\")\n",
        "for i in range(len(X_train)):\n",
        "    if predictions[i] < 0.5:\n",
        "        print(X_train[i], \"\\t\", \"0\")\n",
        "    else:\n",
        "        print(X_train[i], \"\\t\", \"1\")\n",
        "\n",
        "print(\"\\nFinal Weights:\")\n",
        "print(\"w0:\", w0)\n",
        "print(\"w1:\", w1)\n",
        "print(\"w2:\", w2)\n"
      ],
      "metadata": {
        "id": "4B_InltcYVQg",
        "outputId": "1fe70b73-e9ef-4a83-9f4a-712f67440cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input\tPredicted Output\n",
            "[0 0] \t 1\n",
            "[0 1] \t 0\n",
            "[1 0] \t 0\n",
            "[1 1] \t 0\n",
            "\n",
            "Final Weights:\n",
            "w0: 2.8510953865260076\n",
            "w1: -6.19438665631532\n",
            "w2: -6.194150198349799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9i3GBWYRajD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}